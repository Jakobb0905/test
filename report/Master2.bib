@online{01c56e081202b62bd7d3b4f8545775fbPdf,
  title = {01c56e081202b62bd7d3b4f8545775fb.Pdf},
  url = {https://dl.icdst.org/pdfs/files4/01c56e081202b62bd7d3b4f8545775fb.pdf},
  urldate = {2023-04-17},
  file = {C:\Users\pober\Zotero\storage\TFSLNIZZ\01c56e081202b62bd7d3b4f8545775fb.pdf}
}

@online{A16FVariableFocus,
  title = {A-{{16F Variable Focus Lenses}} | {{Variable Focus Lens Technology}} with {{No Moving Parts}} | {{Corning}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/variable-focus-lenses-a-series/varioptic-A-16F.html},
  urldate = {2023-06-23},
  abstract = {The Corning A-16F Variable Focus Lens is the latest and smallest member of the A-Series family, and the smallest lens currently available.},
  langid = {american},
  file = {C:\Users\pober\Zotero\storage\4H224JID\varioptic-A-16F.html}
}

@online{A25HVariableFocus,
  title = {A-{{25H Variable Focus Lenses}} | {{Miniature Industrial Camera Arctic Lens Technology}} | {{Corning}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/variable-focus-lenses-a-series/varioptic-A-25H.html},
  urldate = {2023-06-23},
  abstract = {The Corning A-25H Variable Focus Lens is an excellent fit for low footprint systems requiring fast response time and large focusing range, and is especially suitable for miniature industrial cameras.},
  langid = {american},
  file = {C:\Users\pober\Zotero\storage\LSUTVDMT\varioptic-A-25H.html}
}

@online{A25HVariableFocusa,
  title = {A-{{25H Variable Focus Lenses}} | {{Miniature Industrial Camera Arctic Lens Technology}} | {{Corning}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/variable-focus-lenses-a-series/varioptic-A-25H.html},
  urldate = {2023-06-22},
  abstract = {The Corning A-25H Variable Focus Lens is an excellent fit for low footprint systems requiring fast response time and large focusing range, and is especially suitable for miniature industrial cameras.},
  langid = {american}
}

@online{A39NVariableFocus,
  title = {A-{{39N Variable Focus Lens}} | {{Shock Resistant Auto Focus Technology}} | {{Corning}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/variable-focus-lenses-a-series/varioptic-A-39N.html},
  urldate = {2023-06-23},
  abstract = {The Corning A-39N Variable Focus Lens is perfectly suited for applications such as industrial vision, medical imaging cameras, optical equipment and biometric devices.},
  langid = {american},
  file = {C:\Users\pober\Zotero\storage\T8ZSHXD8\varioptic-A-39N.html}
}

@online{A58NVariableFocus,
  title = {A-{{58N Variable Focus Liquid Lens}} | {{Large Clear Aperture Liquid Lens}} | {{Corning}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/variable-focus-lenses-a-series/varioptic-A-58N.html},
  urldate = {2023-06-23},
  abstract = {The A-58N liquid lens is designed specifically for variable focus products needing a larger clear aperture than our A-39N \& A-25H lens: more specifically designed for optical instruments, like ophthalmology, scientific, life sciences, and microscopes.},
  langid = {american},
  file = {C:\Users\pober\Zotero\storage\ASIX5ZVH\varioptic-A-58N.html}
}

@online{ADA133492Pdf,
  title = {{{ADA133492}}.Pdf},
  url = {https://apps.dtic.mil/sti/pdfs/ADA133492.pdf},
  urldate = {2023-02-22},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\ZXPQG7IK\ADA133492.pdf}
}

@article{annibaleElectricallyTunableLens2015,
  title = {Electrically Tunable Lens Speeds up {{3D}} Orbital Tracking},
  author = {Annibale, Paolo and Dvornikov, Alexander and Gratton, Enrico},
  date = {2015-05-21},
  journaltitle = {Biomedical Optics Express},
  shortjournal = {Biomed Opt Express},
  volume = {6},
  number = {6},
  eprint = {26114037},
  eprinttype = {pmid},
  pages = {2181--2190},
  issn = {2156-7085},
  doi = {10.1364/BOE.6.002181},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4473752/},
  urldate = {2023-06-29},
  abstract = {3D orbital particle tracking is a versatile and effective microscopy technique that allows following fast moving fluorescent objects within living cells and reconstructing complex 3D shapes using laser scanning microscopes. We demonstrated notable improvements in the range, speed and accuracy of 3D orbital particle tracking by replacing commonly used piezoelectric stages with Electrically Tunable Lens (ETL) that eliminates mechanical movement of objective lenses. This allowed tracking and reconstructing shape of structures extending 500 microns in the axial direction. Using the ETL, we tracked at high speed fluorescently labeled genomic loci within the nucleus of living cells with unprecedented temporal resolution of 8ms using a 1.42NA oil-immersion objective. The presented technology is cost effective and allows easy upgrade of scanning microscopes for fast 3D orbital tracking.},
  pmcid = {PMC4473752},
  file = {C:\Users\pober\Zotero\storage\7PTL9QMA\Annibale et al. - 2015 - Electrically tunable lens speeds up 3D orbital tra.pdf}
}

@online{asaenkoImageSharpnessMetric2013,
  type = {Forum post},
  title = {Image Sharpness Metric},
  author = {{asaenko}},
  date = {2013-07-26},
  url = {https://stackoverflow.com/q/17887883},
  urldate = {2023-05-22},
  organization = {Stack Overflow},
  file = {C:\Users\pober\Zotero\storage\5KLQA236\image-sharpness-metric.html}
}

@article{aslantasComparisonDifferentFocus,
  title = {A Comparison of Different Focus Measures for Use in Fusion of Multi-Focus Noisy Images},
  author = {Aslantas, V and Kurban, R},
  abstract = {Impulsive noise (IN) produced by image sensors and/or communication channels corrupts images in many practical applications. This noise may cause miscalculation of sharpness values which, in turn, introduce considerable errors in fused images. In this paper, conventional focus measures and frequency selective weighted median filter (FSWM) based focus measure are evaluated for fusion of multi-focus images in the presence of IN. Experimental results are presented for several sets of images and the results show that FSWM based focus measure can provide better performance than other focus measures.},
  langid = {english},
  keywords = {Am lesen},
  file = {C:\Users\pober\Zotero\storage\UN24XYMU\Aslantas und Kurban - A comparison of different focus measures for use i.pdf}
}

@online{AtherosCSITool,
  title = {Atheros {{CSI}} Tool},
  url = {https://wands.sg/research/wifi/AtherosCSI/},
  urldate = {2024-01-20},
  file = {C:\Users\pober\Zotero\storage\9CQC36JW\AtherosCSI.html}
}

@inproceedings{battenAutofocusingAstigmatismCorrection2000,
  title = {Autofocusing and {{Astigmatism Correction}} in the {{Scanning Electron Microscope}}},
  author = {Batten, Christopher},
  date = {2000},
  url = {https://www.semanticscholar.org/paper/Autofocusing-and-Astigmatism-Correction-in-the-Batten/828ff1be363cc126427c3fbb2dc6f9e92867c445},
  urldate = {2023-06-30},
  abstract = {This work investigates both the theoretical and practical aspects of autofocusing and astigmatism correction in the scanning electron microscope. A general framework is used to divide the problem into four primary areas of concern: noise reduction, regions of interest, sharpness measures, and maximum sharpness search algorithms. Each of these areas is investigated in detail and several novel concepts are introduced including: the use of reduced domain median filters to mitigate limited bandwidth distortion, a method for confining the region of interest to specimen features, more sophisticated maximum sharpness search algorithms such as the variable stepsize search and the Fibonacci search, and interpolation based on a model of variance as a function of defocus. A development testbed was established which allowed for rapid prototyping in MATLAB, implementation in Visual C++, and then final packaging as an ActiveX control. The theoretical work was implemented in a modular component (called SEMimage) for use with the Leo 440 SEM located in the Scientific Imaging Group at the Cambridge University Engineering Department. The framework was used to develop algorithms for full autofocusing, fine autofocusing, real-time autofocusing, and astigmatism correction. Real-time autofocusing enables the software to automatically determine when an image has become defocused and to then take appropriate action to move the image back into focus. Real-time beam alignment and signal to noise calculation were also implemented. SEMimage was tested on the instrument and provided an effective means for automated focusing and astigmatism correction. The fine autofocusing provided by SEMimage is relatively fast and accurate, and the real-time autofocusing provides a unique method for keeping the instrument in focus.},
  file = {C:\Users\pober\Zotero\storage\ZTPLY7YE\Batten - 2000 - Autofocusing and Astigmatism Correction in the Sca.pdf}
}

@article{battenSharpnessSearchAlgorithms2001,
  title = {Sharpness {{Search Algorithms}} for {{Automatic Focusing}} in the {{Scanning Electron Microscope}}},
  author = {Batten, C F and Holburn, D M and Breton, B C and Caldwell, N H M},
  date = {2001},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\TK6EZFQI\Batten et al. - 2001 - Sharpness Search Algorithms for Automatic Focusing.pdf}
}

@online{beckerwww.kalmanfilter.netOnlineKalmanFilter,
  title = {Online {{Kalman Filter Tutorial}}},
  author = {Becker (www.kalmanfilter.net), Alex},
  url = {https://www.kalmanfilter.net/},
  urldate = {2024-01-14},
  abstract = {Easy and intuitive Kalman Filter tutorial},
  langid = {english}
}

@book{bergeLiquidLensTechnology2005,
  title = {Liquid Lens Technology: {{Principle}} of Electrowetting Based Lenses and Applications to Imaging},
  shorttitle = {Liquid Lens Technology},
  author = {Berge, Bruno},
  date = {2005-01-01},
  journaltitle = {Proceedings of the IEEE International Conference on Micro Electro Mechanical Systems (MEMS)},
  pages = {230},
  doi = {10.1109/MEMSYS.2005.1453908},
  abstract = {The principle of liquid lenses based on electrowetting are presented, with emphasis on the key features that enables to produce a useful component for complex optical systems: equality of the densities of the two non miscible liquids, centering mean for the liquid-liquid interface which allows the optical axis to remain always stable, choice of the suitable insulating material for the supporting body etc... We presented experimental results discussed in the light of a modelization.},
  isbn = {978-0-7803-8732-4},
  pagetotal = {227},
  file = {C:\Users\pober\Zotero\storage\KWXQQK7Y\Berge - 2005 - Liquid lens technology Principle of electrowettin.pdf}
}

@online{Brechungsindex,
  title = {Brechungsindex},
  url = {https://www.spektrum.de/lexikon/optik/brechungsindex/461},
  urldate = {2023-06-28},
  abstract = {Brechungsindex, Brechzahl, Brechungskoeffizient, -quotient, -vermögen, -exponent, Formelzeichen n, eine Materialkonstante, die für die Ausbreitung…},
  langid = {ngerman},
  organization = {Spektrum.de},
  file = {C:\Users\pober\Zotero\storage\SGLLA95W\461.html}
}

@online{BustedMythOpenloop,
  title = {Busted! {{The Myth}} of {{Open-loop Phase-detection Autofocus}}: {{Digital Photography Review}}},
  url = {https://www.dpreview.com/articles/5402438893/busted-the-myth-of-open-loop-phase-detection-autofocus},
  urldate = {2023-02-21},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\34PKZSI6\busted-the-myth-of-open-loop-phase-detection-autofocus.html}
}

@article{chenElectricallyTunableLenses2021,
  title = {Electrically {{Tunable Lenses}}: {{A Review}}},
  shorttitle = {Electrically {{Tunable Lenses}}},
  author = {Chen, Leihao and Ghilardi, Michele and Busfield, James J. C. and Carpi, Federico},
  date = {2021},
  journaltitle = {Frontiers in Robotics and AI},
  volume = {8},
  issn = {2296-9144},
  url = {https://www.frontiersin.org/articles/10.3389/frobt.2021.678046},
  urldate = {2023-02-17},
  abstract = {Optical lenses with electrically controllable focal length are of growing interest, in order to reduce the complexity, size, weight, response time and power consumption of conventional focusing/zooming systems, based on glass lenses displaced by motors. They might become especially relevant for diverse robotic and machine vision-based devices, including cameras not only for portable consumer electronics (e.g. smart phones) and advanced optical instrumentation (e.g. microscopes, endoscopes, etc.), but also for emerging applications like small/micro-payload drones and wearable virtual/augmented-reality systems. This paper reviews the most widely studied strategies to obtain such varifocal “smart lenses”, which can electrically be tuned, either directly or via electro-mechanical or electro-thermal coupling. Only technologies that ensure controllable focusing of multi-chromatic light, with spatial continuity (i.e. continuous tunability) in wavefronts and focal lengths, as required for visible-range imaging, are considered. Both encapsulated fluid-based lenses and fully elastomeric lenses are reviewed, ranging from proof-of-concept prototypes to commercially available products. They are classified according to the focus-changing principles of operation, and they are described and compared in terms of advantages and drawbacks. This systematic overview should help to stimulate further developments in the field.},
  keywords = {Am lesen,Wichtig},
  file = {C:\Users\pober\Zotero\storage\W2EK8HIF\Chen et al. - 2021 - Electrically Tunable Lenses A Review.pdf}
}

@article{chenPassiveAutofocusCamera2010,
  title = {A Passive Auto-Focus Camera Control System},
  author = {Chen, Chih-Yung and Hwang, Rey-Chue and Chen, Yu-Ju},
  date = {2010-01-01},
  journaltitle = {Applied Soft Computing},
  shortjournal = {Applied Soft Computing},
  volume = {10},
  number = {1},
  pages = {296--303},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2009.07.007},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494609001148},
  urldate = {2023-02-22},
  abstract = {This paper presents a passive auto-focus camera control system which can easily achieve the function of auto-focus with no necessary of any active component (e.g., infrared or ultrasonic sensor) in comparison with the conventional active focus system. To implement the technique we developed, the hardware system including the adjustable lens with CMOS sensor and servo motor, an 8051 image capture micro-controller, a field programmable gate array (FPGA) sharpness measurement circuit, a pulse width modulation (PWM) controller, and a personal digital assistant (PDA) image displayer was constructed. The discrete wavelet transformation (DWT), the morphology edge enhancement sharpness measurement algorithms, and the self-organizing map (SOM) neural network were used in developing the control mechanism of the system. Compared with other passive auto-focus methods, the method we proposed has the advantages of lower computational complexity and easier hardware implementation.},
  langid = {english},
  keywords = {Auto-focus system,Discrete wavelet transformation,Morphology,Passive,Self-organizing map,Sharpness measurement,Zu lesen},
  file = {C:\Users\pober\Zotero\storage\YDP2P36S\S1568494609001148.html}
}

@online{ConceptsOrthogonalFrequency,
  title = {Concepts of {{Orthogonal Frequency Division Multiplexing}} ({{OFDM}}) and 802.11 {{WLAN}}},
  url = {https://rfmw.em.keysight.com/wireless/helpfiles/89600b/webhelp/subsystems/wlan-ofdm/content/ofdm_basicprinciplesoverview.htm},
  urldate = {2024-01-20},
  file = {C:\Users\pober\Zotero\storage\D5XITE55\ofdm_basicprinciplesoverview.html}
}

@online{Controllers,
  title = {Controllers},
  url = {https://www.optotune.com/controllers},
  urldate = {2023-06-24},
  langid = {american},
  organization = {Optotune},
  file = {C:\Users\pober\Zotero\storage\LSRVEG4J\controllers.html}
}

@online{CorningVariopticFokussierbare,
  title = {Corning® Varioptic® fokussierbare Flüssiglinsen | Edmund Optics},
  url = {https://www.edmundoptics.de/f/corning-varioptic-variable-focus-liquid-lenses/15042/},
  urldate = {2023-04-20},
  abstract = {Corning® Varioptic® Variable Focus Liquid Lenses vary their focal length by user applied voltage. ✓ Shop now with Edmund Optics!},
  langid = {ngerman},
  file = {C:\Users\pober\Zotero\storage\P5ZNMT7C\15042.html}
}

@online{CorningVariopticLenses,
  title = {{{Corning}}® {{Varioptic}}® {{Lenses Technology}} | {{Adjustable Liquid Lenses}} | {{Corning}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/varioptic-technology.html},
  urldate = {2023-04-20},
  abstract = {Corning® Varioptic® Lenses has created a programmable lens that can be reconfigured on demand by a voltage change. The liquid lens can adapt rapidly and continuously from diverging to converging and be modeled to support demanding variable focus applications.},
  langid = {american},
  file = {C:\Users\pober\Zotero\storage\8HWU7BGX\varioptic-technology.html}
}

@inproceedings{delgado-olabarriagaSubjectiveObjectiveEvaluation1996,
  title = {Subjective and Objective Evaluation of Image Sharpness: Behavior of the Region-Based Image Edge Profile Acutance Measure},
  shorttitle = {Subjective and Objective Evaluation of Image Sharpness},
  author = {Delgado-Olabarriaga, Silvia and Rangayyan, Rangaraj M.},
  editor = {Kundel, Harold L.},
  date = {1996-03-27},
  pages = {154--162},
  location = {Newport Beach, CA},
  doi = {10.1117/12.236852},
  abstract = {We recently proposed a region-based measure of image edge profile acutance to characterize the sharpness of a region of interest. In this paper we study the capability of the acutance measure to analyze relative sharpness in the presence of blurring and noise by comparing acutance to other measures of distortion and to subjective evaluation. The purpose of the experiment was to organize an image set in increasing order of sharpness with results obtained by objective image quality measures (acutarice, mean squared error, normalized error, and normalized mean squared error) and to compare the results with subjective evaluation. A psychometric experiment was developed to perform sorting according to the subjective notion of sharpness. The region-based image edge profile acutance measure provided results that agree more closely with subjective evaluation of relative sharpness than the other measures studied. The acutance measure also exhibited a good level of immunity to noise, whereas the other measures provided ordering according to noise rather than sharpness.},
  eventtitle = {Medical {{Imaging}} 1996},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\5YUITI5P\Delgado-Olabarriaga und Rangayyan - 1996 - Subjective and objective evaluation of image sharp.pdf}
}

@article{dimeoFastAccurateAutofocus2021,
  title = {Fast and Accurate Autofocus Control Using {{Gaussian}} Standard Deviation and Gradient-Based Binning},
  author = {DiMeo, Peter and Sun, Lu and Du, Xian},
  date = {2021-06-21},
  journaltitle = {Optics Express},
  shortjournal = {Opt. Express, OE},
  volume = {29},
  number = {13},
  pages = {19862--19878},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.425118},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-29-13-19862},
  urldate = {2023-04-26},
  abstract = {We propose a fast and accurate autofocus algorithm using Gaussian standard deviation and gradient-based binning. Rather than iteratively searching for the optimal focus using an optimization process, the proposed algorithm directly calculates the mean of the Gaussian shaped focus measure (FM) curve to find the optimal focus location and uses the FM curve standard deviation to adapt the motion step size. The calculation only requires 3-4 defocused images to identify the center location of the FM curve. Furthermore, by assigning motion step sizes based on the FM curve standard deviation, the magnitude of the motion step is adaptively controlled according to the defocused measure, thus avoiding overshoot and unneeded image processing. Our experiment verified the proposed method is faster than the state-of-the-art Adaptive Hill-Climbing (AHC) and offers satisfactory accuracy as measured by root-mean-square error. The proposed method requires 80\% fewer images for focusing compared to the AHC method. Moreover, due to this significant reduction in image processing, the proposed method reduces autofocus time to completion by 22\% compared to the AHC method. Similar performance of the proposed method was observed in both well-lit and low-lighting conditions.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\QL938W3H\DiMeo et al. - 2021 - Fast and accurate autofocus control using Gaussian.pdf}
}

@article{dodge3LANPCVs3LNPC2021,
  title = {{{3L-ANPC}} vs. {{3L-NPC Inverters}}},
  author = {Dodge, Jonathan},
  date = {2021},
  abstract = {Three-level diode neutral point clamped (3L-NPC) and active neutral point clamped (3L-ANPC) inverters share fundamental features, including an operating voltage limit that is higher than the individual power semiconductor ratings, reduced switching loss, and three-level output voltages. Neutral point voltage balancing algorithms remain unchanged. In the 3L-ANPC, two FETs replace two diodes in each leg, and therefore 3L-ANPC is higher cost. Depending on modulation, the additional 3L-ANPC switch states can be used to reduce power loss, double the output frequency, and/or affect switch utilization. Midpoints between series FETs are periodically clamped, eliminating the need for balancing resistors. Additional destructive switch states must be avoided. Operation of each inverter type is briefly explained, followed by a review of some 3L-ANPC modulation strategies, and finally by steady state power loss calculations. These calculations are very useful for comparing 3L-NPC and 3L-ANPC topologies and modulation strategies, and for selecting the number and type of power semiconductors.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\9W6RXAFQ\Dodge - 2021 - 3L-ANPC vs. 3L-NPC Inverters.pdf}
}

@online{ECC1CController,
  title = {{{ECC-1C}} Controller},
  url = {https://www.optotune.com/ecc-1c},
  urldate = {2023-04-20},
  langid = {american},
  organization = {Optotune},
  file = {C:\Users\pober\Zotero\storage\8MNK4DL3\ecc-1c.html}
}

@article{efstathiouElectricallyTunableLenses2021,
  title = {Electrically Tunable Lenses – Eliminating Mechanical Axial Movements during High-Speed {{3D}} Live Imaging},
  author = {Efstathiou, Christoforos and Draviam, Viji M.},
  date = {2021-08-15},
  journaltitle = {Journal of Cell Science},
  volume = {134},
  number = {16},
  pages = {jcs258650},
  issn = {0021-9533, 1477-9137},
  doi = {10.1242/jcs.258650},
  url = {https://journals.biologists.com/jcs/article/134/16/jcs258650/271866/Electrically-tunable-lenses-eliminating-mechanical},
  urldate = {2023-06-29},
  abstract = {The successful investigation of photosensitive and dynamic biological events, such as those in a proliferating tissue or a dividing cell, requires non-intervening high-speed imaging techniques. Electrically tunable lenses (ETLs) are liquid lenses possessing shape-changing capabilities that enable rapid axial shifts of the focal plane, in turn achieving acquisition speeds within the millisecond regime. These human-eye-inspired liquid lenses can enable fast focusing and have been applied in a variety of cell biology studies. Here, we review the history, opportunities and challenges underpinning the use of costeffective high-speed ETLs. Although other, more expensive solutions for three-dimensional imaging in the millisecond regime are available, ETLs continue to be a powerful, yet inexpensive, contender for livecell microscopy.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\E86PBEMT\jcs258650.pdf}
}

@article{efstathiouElectricallyTunableLenses2021a,
  title = {Electrically Tunable Lenses – Eliminating Mechanical Axial Movements during High-Speed {{3D}} Live Imaging},
  author = {Efstathiou, Christoforos and Draviam, Viji M.},
  date = {2021-08-19},
  journaltitle = {Journal of Cell Science},
  shortjournal = {Journal of Cell Science},
  volume = {134},
  number = {16},
  pages = {jcs258650},
  issn = {0021-9533},
  doi = {10.1242/jcs.258650},
  url = {https://doi.org/10.1242/jcs.258650},
  urldate = {2023-06-23},
  abstract = {The successful investigation of photosensitive and dynamic biological events, such as those in a proliferating tissue or a dividing cell, requires non-intervening high-speed imaging techniques. Electrically tunable lenses (ETLs) are liquid lenses possessing shape-changing capabilities that enable rapid axial shifts of the focal plane, in turn achieving acquisition speeds within the millisecond regime. These human-eye-inspired liquid lenses can enable fast focusing and have been applied in a variety of cell biology studies. Here, we review the history, opportunities and challenges underpinning the use of cost-effective high-speed ETLs. Although other, more expensive solutions for three-dimensional imaging in the millisecond regime are available, ETLs continue to be a powerful, yet inexpensive, contender for live-cell microscopy.},
  file = {C\:\\Users\\pober\\Zotero\\storage\\JS8D2ZST\\Efstathiou und Draviam - 2021 - Electrically tunable lenses – eliminating mechanic.pdf;C\:\\Users\\pober\\Zotero\\storage\\QN8NWNSY\\Electrically-tunable-lenses-eliminating-mechanical.html}
}

@online{falcaoAnswerImageSharpness2015,
  title = {Answer to "{{Image}} Sharpness Metric"},
  author = {Falcao, Thiago},
  date = {2015-07-22},
  url = {https://stackoverflow.com/a/31573693},
  urldate = {2023-05-22},
  organization = {Stack Overflow},
  file = {C:\Users\pober\Zotero\storage\7AUHNL9C\image-sharpness-metric.html}
}

@inreference{Faltungsmatrix2021,
  title = {Faltungsmatrix},
  booktitle = {Wikipedia},
  date = {2021-09-18T19:30:39Z},
  url = {https://de.wikipedia.org/w/index.php?title=Faltungsmatrix&oldid=215704205},
  urldate = {2023-04-20},
  abstract = {Faltungsmatrizen (auch Kern, Filterkern, Filteroperator, Filtermaske oder Faltungskern genannt, englisch convolution kernel) werden in der digitalen Bildverarbeitung für Filter verwendet. Es handelt sich meist um quadratische Matrizen ungerader Abmessungen in unterschiedlichen Größen. Viele Bildverarbeitungsoperationen können als lineares System dargestellt werden, wobei eine diskrete Faltung, eine lineare Operation, angewandt wird.  Für diskrete zweidimensionale Funktionen (digitale Bilder) ergibt sich folgende Berechnungsformel für die diskrete Faltung:                                   I                        ∗                             (         x         ,         y         )         =                    ∑                        i             =             1                                   n                                        ∑                        j             =             1                                   n                             I         (         x         −         i         +         a         ,                  y         −         j         +         a         )         k         (         i         ,         j         )                 \{\textbackslash displaystyle I\textasciicircum\{*\}(x,y)=\textbackslash sum \_\{i=1\}\textasciicircum\{n\}\textbackslash sum \_\{j=1\}\textasciicircum\{n\}I(x-i+a,\textbackslash;y-j+a)k(i,j)\}                                      I                        ∗                             (         x         ,         y         )                 \{\textbackslash displaystyle I\textasciicircum\{*\}(x,y)\}    ist hier das Ergebnispixel,                         I                 \{\textbackslash displaystyle I\}    ist das Bild, auf welches der Filter angewandt wird,                         a                 \{\textbackslash displaystyle a\}    ist die Koordinate des Mittelpunkts in der quadratischen Faltungsmatrix, und                         k         (         i         ,         j         )                 \{\textbackslash displaystyle k(i,j)\}    ist ein Element der Faltungsmatrix. Um den Mittelpunkt eindeutig definieren zu können, sind ungerade Abmessungen der Faltungsmatrizen notwendig. Bei 3×3-Faltungsmatrizen ist                         n         =         3                 \{\textbackslash displaystyle n=3\}    und                         a         =         2                 \{\textbackslash displaystyle a=2\}   . Bei 5×5-Faltungsmatrizen ist                         n         =         5                 \{\textbackslash displaystyle n=5\}    und                         a         =         3                 \{\textbackslash displaystyle a=3\}   .},
  langid = {ngerman},
  annotation = {Page Version ID: 215704205},
  file = {C:\Users\pober\Zotero\storage\JYK5XFP2\Faltungsmatrix.html}
}

@online{FaltungUndImpulsantwort,
  title = {Faltung Und {{Impulsantwort}} - {{Multimediale Signalverarbeitung}}, {{Teil}} 3, {{Kapitel}} 1},
  url = {https://www.mathematik.uni-marburg.de/~thormae/lectures/mmk/mmk_3_1_ger_web.html#1},
  urldate = {2023-04-20},
  file = {C:\Users\pober\Zotero\storage\ZZ95WGCF\mmk_3_1_ger_web.html}
}

@online{FluessiglinsenBildverarbeitungEdmund,
  title = {Flüssiglinsen in der Bildverarbeitung | Edmund Optics},
  url = {https://www.edmundoptics.de/knowledge-center/application-notes/imaging/liquid-lenses-in-imaging/},
  urldate = {2023-04-20},
  abstract = {Flüssiglinsen ⇒ Flüssiglinsen ⇒ schnelle Anpassung an Objekte in verschiedenen Arbeitsabständen ✓ hoher Durchsatz bei industrieller Bildverarbeitung. Mehr Infos bei EO!},
  langid = {ngerman}
}

@online{FocusTunableLenses,
  title = {Focus Tunable Lenses},
  url = {https://www.optotune.com/focus-tunable-lenses},
  urldate = {2023-06-23},
  abstract = {Optotune develops and manufactures industry shaping active optical components that allow customers around the globe to innovate. Founded in 2008, we started out with our core technology of focus tunable lenses, which was inspired by the working principle of the human eye. Laser speckle reducers, 2D},
  langid = {american},
  organization = {Optotune},
  file = {C:\Users\pober\Zotero\storage\L4CS3HL6\focus-tunable-lenses.html}
}

@online{FocusTunableLensesa,
  title = {Focus Tunable Lenses},
  url = {https://www.optotune.com/focus-tunable-lenses},
  urldate = {2023-04-20},
  abstract = {Optotune develops and manufactures industry shaping active optical components that allow customers around the globe to innovate. Founded in 2008, we started out with our core technology of focus tunable lenses, which was inspired by the working principle of the human eye. Laser speckle reducers, 2D},
  langid = {american},
  organization = {Optotune},
  file = {C:\Users\pober\Zotero\storage\Y9MSAH69\focus-tunable-lenses.html}
}

@article{frickeNonContactDermatoscopeUltraBright2019,
  title = {Non-{{Contact Dermatoscope}} with {{Ultra-Bright Light Source}} and {{Liquid Lens-Based Autofocus Function}}},
  author = {Fricke, Dierk and Denker, Evgeniia and Heratizadeh, Annice and Werfel, Thomas and Wollweber, Merve and Roth, Bernhard},
  date = {2019-01},
  journaltitle = {Applied Sciences},
  volume = {9},
  number = {11},
  pages = {2177},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app9112177},
  url = {https://www.mdpi.com/2076-3417/9/11/2177},
  urldate = {2023-06-22},
  abstract = {Dermatoscopes are routinely used in skin cancer screening but are rarely employed for the diagnosis of other skin conditions. Broader application is promising from a diagnostic point of view as biopsies for differential diagnosis may be avoided but it requires non-contact devices allowing a comparably large field of view that are not commercially available today. Autofocus and color reproducibility are specific challenges for the development of dermatoscopy for application beyond cancer screening. We present a prototype for such a system including solutions for autofocus and color reproducibility independent of ambient lighting. System performance includes sufficiently high feature resolution of up to 30 µm and feature size scaling fulfilling the requirements to apply the device in regular skin cancer screening.},
  issue = {11},
  langid = {english},
  keywords = {biomedical imaging,dermatoscopy,skin screening},
  file = {C:\Users\pober\Zotero\storage\B3DCRWFN\Fricke et al. - 2019 - Non-Contact Dermatoscope with Ultra-Bright Light S.pdf}
}

@online{gillumAnswerImageSharpness2015,
  title = {Answer to "{{Image}} Sharpness Metric"},
  author = {Gillum, Eliot},
  date = {2015-07-11},
  url = {https://stackoverflow.com/a/31352152},
  urldate = {2023-05-22},
  organization = {Stack Overflow},
  file = {C:\Users\pober\Zotero\storage\LMJJSNMR\image-sharpness-metric.html}
}

@article{gonzalezDigitalImageProcessing2009,
  title = {Digital {{Image Processing}}, {{Third Edition}}},
  author = {Gonzalez, Rafael C. and Woods, Richard E. and Masters, Barry R.},
  date = {2009},
  journaltitle = {Journal of Biomedical Optics},
  shortjournal = {J. Biomed. Opt.},
  volume = {14},
  number = {2},
  pages = {029901},
  issn = {10833668},
  doi = {10.1117/1.3115362},
  url = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.3115362},
  urldate = {2023-04-17},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\RZ6KEGC4\Digital.Image.Processing.3rd.Edition.www.EBooksWorld.ir.pdf}
}

@online{gordyAnswerImageSharpness2015,
  title = {Answer to "{{Image}} Sharpness Metric"},
  author = {{gordy}},
  date = {2015-07-11},
  url = {https://stackoverflow.com/a/31352214},
  urldate = {2023-05-22},
  organization = {Stack Overflow},
  file = {C:\Users\pober\Zotero\storage\XMZV8ZGQ\image-sharpness-metric.html}
}

@article{groenComparisonDifferentFocus1985,
  title = {A Comparison of Different Focus Functions for Use in Autofocus Algorithms},
  author = {Groen, Frans C. A. and Young, Ian T. and Ligthart, Guido},
  date = {1985},
  journaltitle = {Cytometry},
  volume = {6},
  number = {2},
  pages = {81--91},
  issn = {1097-0320},
  doi = {10.1002/cyto.990060202},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cyto.990060202},
  urldate = {2023-04-21},
  abstract = {A number of functions for the autofocusing of microscopes and other optical instruments are to be found in the literature. In this article we compare 11 of them to determine, in an objective manner, which functions are most suitable for implementation with real-time video acquisition systems. Three different images, each representing a typical class of image, are used in the comparison. Among the best focus functions found in our study are the squared magnitude gradient, the squared Laplacian, and the normalized image standard deviation.},
  langid = {english},
  keywords = {Am lesen,comparative study,Focus function,gradient,image focus,Laplacian},
  file = {C\:\\Users\\pober\\Zotero\\storage\\TI9TAZV7\\Groen et al. - 1985 - A comparison of different focus functions for use .pdf;C\:\\Users\\pober\\Zotero\\storage\\P7V842WR\\cyto.html}
}

@online{grossWieFunktionierenModerne,
  title = {Wie funktionieren moderne AF-Antriebe in Objektiven?},
  author = {Groß, Dominic},
  url = {https://www.connect-living.de/ratgeber/moderne-af-antriebe-teil-1-1281448.html},
  urldate = {2023-06-29},
  abstract = {Unser Wissensbeitrag erläutert den Weg vom Gleichstrom- über den Ultraschallantrieb zu neuen Linearmotoren.},
  langid = {ngerman},
  organization = {connect-living},
  file = {C:\Users\pober\Zotero\storage\W6UJGBNB\moderne-af-antriebe-teil-1-1281448.html}
}

@online{GrundlagenFluessiglinsenEdmund,
  title = {Grundlagen zu Flüssiglinsen | Edmund Optics},
  url = {https://www.edmundoptics.de/knowledge-center/application-notes/imaging/introduction-to-liquid-lenses/},
  urldate = {2023-06-22},
  abstract = {Flüssiglinsen ⇒ elektronische Fokusänderung für eine verbesserte Leistung von Bildverarbeitungssystemen. Mehr Infos jetzt bei EO!},
  langid = {ngerman},
  file = {C:\Users\pober\Zotero\storage\ME6DPUI2\introduction-to-liquid-lenses.html}
}

@article{gulatiCY8CKIT037PSoCMotor,
  title = {{{CY8CKIT-037 PSoC}}® 4 {{Motor Control Evaluation Kit Guide}}},
  author = {Gulati, Anshul},
  number = {001},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\4JK4FVLK\Gulati - CY8CKIT-037 PSoC® 4 Motor Control Evaluation Kit G.pdf}
}

@online{guWiFibasedRealtimeBreathing2019,
  title = {{{WiFi-based Real-time Breathing}} and {{Heart Rate Monitoring}} during {{Sleep}}},
  author = {Gu, Yu and Zhang, Xiang and Liu, Zhi and Ren, Fuji},
  date = {2019-08-14},
  eprint = {1908.05108},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/1908.05108},
  urldate = {2023-12-11},
  abstract = {Good quality sleep is essential for good health and sleep monitoring becomes a vital research topic. This paper provides a low cost, continuous and contactless WiFi-based vital signs (breathing and heart rate) monitoring method. In particular, we set up the antennas based on Fresnel diffraction model and signal propagation theory, which enhances the detection of weak breathing/heartbeat motion. We implement a prototype system using the off-shelf devices and a real-time processing system to monitor vital signs in real time. The experimental results indicate the accurate breathing rate and heart rate detection performance. To the best of our knowledge, this is the first work to use a pair of WiFi devices and omnidirectional antennas to achieve real-time individual breathing rate and heart rate monitoring in different sleeping postures.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Human-Computer Interaction,Electrical Engineering and Systems Science - Signal Processing},
  file = {C:\Users\pober\Zotero\storage\L3363AIN\Gu et al. - 2019 - WiFi-based Real-time Breathing and Heart Rate Moni.pdf}
}

@online{HandsonWirelessSensing,
  title = {Hands-on {{Wireless Sensing}} with {{Wi-Fi}}: {{A Tutorial}} | {{Hands-on Wireless Sensing}} with {{Wi-Fi}}: {{A Tutorial}}},
  shorttitle = {Hands-on {{Wireless Sensing}} with {{Wi-Fi}}},
  url = {http://tns.thss.tsinghua.edu.cn/wst/localhost/wst/},
  urldate = {2023-12-11},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\DB7XP8LU\wst.html}
}

@article{hasanTunablefocusLensAdaptive2017,
  title = {Tunable-Focus Lens for Adaptive Eyeglasses},
  author = {Hasan, Nazmul and Banerjee, Aishwaryadev and Kim, Hanseup and Mastrangelo, Carlos H.},
  date = {2017-01-23},
  journaltitle = {Optics Express},
  shortjournal = {Opt. Express},
  volume = {25},
  number = {2},
  pages = {1221},
  issn = {1094-4087},
  doi = {10.1364/OE.25.001221},
  url = {https://opg.optica.org/abstract.cfm?URI=oe-25-2-1221},
  urldate = {2023-02-22},
  abstract = {We demonstrate the implementation of a compact tunable-focus liquid lens suitable for adaptive eyeglass application. The lens has an aperture diameter of 32 mm, optical power range of 5.6 diopter, and electrical power consumption less than 20 mW. The lens inclusive of its piezoelectric actuation mechanism is 8.4 mm thick and weighs 14.4 gm. The measured lens RMS wavefront aberration error was between 0.73 µm and 0.956 µm.},
  langid = {english},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\T6R6GIQ9\Hasan et al. - 2017 - Tunable-focus lens for adaptive eyeglasses.pdf}
}

@book{hechtOptik,
  title = {Optik},
  author = {Hecht, Eugene},
  edition = {7.},
  publisher = {De Gruyter},
  isbn = {978-3-11-052664-6}
}

@article{heheModifiedFastClimbing2003,
  title = {Modified Fast Climbing Search Auto-Focus Algorithm with Adaptive Step Size Searching Technique for Digital Camera},
  author = {{He He} and {Rongzhen Zhou} and {Zhiliang Hong}},
  date = {2003-05},
  journaltitle = {IEEE Transactions on Consumer Electronics},
  shortjournal = {IEEE Trans. Consumer Electron.},
  volume = {49},
  number = {2},
  pages = {257--262},
  issn = {0098-3063},
  doi = {10.1109/TCE.2003.1209511},
  url = {http://ieeexplore.ieee.org/document/1209511/},
  urldate = {2023-02-22},
  abstract = {A practical real-time auto-focus algorithm for a digital camera is presented, and it improves the reliability and speed of the auto-focus process, especially suitable for a mega-pixel high definition camera. The proposed algorithm adopts threshold gradient and edge point count technique besides focus value function, instead of the traditional two-stage climbing search algorithm that uses the focus value function only. Additionally, a relative difference ratio circuit is also proposed, which can implement adaptive step size searching to increase the searching speed. By adopting the modified algorithm on the prototype of our mega-pixel digital camera, the real-time auto-focus function is verified. The proposed algorithm is implemented in a test camera chip that has been manufactured in 0.25/spl mu/m CMOS digital process.},
  langid = {english},
  keywords = {Zu lesen}
}

@article{hendriksVariableLiquidLenses2006,
  title = {Variable Liquid Lenses for Electronic Products},
  author = {Hendriks, Benno and Kuiper, Stein and As, Marco and Renders, Christel and Tukker, Teus},
  date = {2006-01-31},
  journaltitle = {Proceedings of SPIE - The International Society for Optical Engineering},
  shortjournal = {Proceedings of SPIE - The International Society for Optical Engineering},
  doi = {10.1117/12.668085},
  abstract = {The design, manufacturing and application of variable liquid lenses are discussed. The interface between the two immiscible liquids that forms the lens can be altered with a voltage. Results are presented of applying this lens in miniature autofocus and zoom cameras, in optical recording and in illumination systems.},
  file = {C:\Users\pober\Zotero\storage\G2B9HV2U\Hendriks et al. - 2006 - Variable liquid lenses for electronic products.pdf}
}

@inproceedings{hernandezDenseScalableSoil2021,
  title = {Towards {{Dense}} and {{Scalable Soil Sensing Through Low-Cost WiFi Sensing Networks}}},
  booktitle = {2021 {{IEEE}} 46th {{Conference}} on {{Local Computer Networks}} ({{LCN}})},
  author = {Hernandez, Steven M. and Erdag, Deniz and Bulut, Eyuphan},
  date = {2021-10-04},
  pages = {549--556},
  publisher = {IEEE},
  location = {Edmonton, AB, Canada},
  doi = {10.1109/LCN52139.2021.9525003},
  url = {https://ieeexplore.ieee.org/document/9525003/},
  urldate = {2024-01-22},
  abstract = {Precision agriculture uses precise sensor data collected throughout farmland to give farmers better insight into their land, allowing for greater crop yields and reduced resource usage. However, existing solutions require high hardware costs thus limiting large scale deployments. To address that, we propose a low-cost and scalable solution for sensing physical attributes of soil using IoT based WiFi sensing devices. By understanding variations in WiFi radio signals with channel state information (CSI) and machine learning models, we evaluate the proposed soil sensing system through experiments on physical soil traits such as soil moisture content, soil texture and position. Moreover, we also demonstrate how a mesh network of WiFi sensing devices allows us to predict the physical traits of the soil in the area between each pair of sensors, allowing for an increase in sensing area coverage as nodes are added.},
  eventtitle = {2021 {{IEEE}} 46th {{Conference}} on {{Local Computer Networks}} ({{LCN}})},
  isbn = {978-1-66541-886-7},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\W3BZDDF4\Hernandez et al. - 2021 - Towards Dense and Scalable Soil Sensing Through Lo.pdf}
}

@online{HintergrundinformationenOptischenSpezifikationen,
  title = {Hintergrundinformationen zu optischen Spezifikationen},
  url = {https://www.edmundoptics.de/knowledge-center/application-notes/optics/understanding-optical-specifications/},
  urldate = {2023-06-29},
  langid = {ngerman},
  file = {C:\Users\pober\Zotero\storage\GRNGTWJA\understanding-optical-specifications.html}
}

@online{HintergrundinformationenOptischenSpezifikationena,
  title = {Hintergrundinformationen zu optischen Spezifikationen},
  url = {https://www.edmundoptics.de/knowledge-center/application-notes/optics/understanding-optical-specifications/},
  urldate = {2023-06-28},
  langid = {ngerman},
  file = {C:\Users\pober\Zotero\storage\TU2ZKTTB\understanding-optical-specifications.html}
}

@article{huLargeDepthoffield3D2019,
  title = {Large Depth-of-Field {{3D}} Shape Measurement Using an Electrically Tunable Lens},
  author = {Hu, Xiaowei and Wang, Guijin and Zhang, Yujin and Yang, Huazhong and Zhang, Song},
  date = {2019-10-14},
  journaltitle = {Optics Express},
  shortjournal = {Opt. Express, OE},
  volume = {27},
  number = {21},
  pages = {29697--29709},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.27.029697},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-27-21-29697},
  urldate = {2023-04-20},
  abstract = {The state-of-the-art 3D shape measurement system has rather shallow working volume due to the limited depth-of-field (DOF) of conventional lens. In this paper, we propose to use the electrically tunable lens to substantially enlarge the DOF. Specifically, we capture always in-focus phase-shifted fringe patterns by precisely synchronizing the tunable lens attached to the camera with the image acquisition and the pattern projection; we develop a phase unwrapping framework that fully utilizes the geometric constraint from the camera focal length setting; and we pre-calibrate the system under different focal distance to reconstruct 3D shape from unwrapped phase map. To validate the proposed idea, we developed a prototype system that can perform high-quality measurement for the depth range of approximately 1,000 mm (400 mm \&\#x2013; 1400 mm) with the measurement error of 0.05\&\#x0025;. Furthermore, we demonstrated that such a technique can be used for real-time 3D shape measurement by experimentally measuring moving objects.},
  langid = {english},
  keywords = {Laser materials processing,Optical systems,Phase unwrapping,Speckle patterns,Three dimensional measurement,Tunable lenses},
  file = {C:\Users\pober\Zotero\storage\Y3EZ8I44\Hu et al. - 2019 - Large depth-of-field 3D shape measurement using an.pdf}
}

@online{IntroductionEMVA,
  title = {Introduction – {{EMVA}}},
  url = {https://www.emva.org/standards-technology/genicam/introduction-new/},
  urldate = {2023-05-29},
  file = {C:\Users\pober\Zotero\storage\FNJN8H9T\introduction-new.html}
}

@inproceedings{kackerLinkAnalysisLiquid2021,
  title = {Link Analysis for a Liquid Lens Beam Steering System, the Miniature Optical Steered Antenna for Intersatellite Communication: {{MOSAIC}}},
  shorttitle = {Link Analysis for a Liquid Lens Beam Steering System, the Miniature Optical Steered Antenna for Intersatellite Communication},
  author = {Kacker, Shreeyam and Cierny, Ondrej and Boyer, Jared and Cahoy, Kerri},
  date = {2021-03-05},
  pages = {25},
  doi = {10.1117/12.2582607},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\P6XEF8DF\Kacker et al. - 2021 - Link analysis for a liquid lens beam steering syst.pdf}
}

@inreference{KarlPinczolits2023,
  title = {Karl Pinczolits},
  booktitle = {Wikipedia},
  date = {2023-07-05T12:26:54Z},
  url = {https://de.wikipedia.org/w/index.php?title=Karl_Pinczolits&oldid=235205851},
  urldate = {2024-01-24},
  abstract = {Karl Pinczolits (* 25. März 1958) ist ein österreichischer Unternehmensberater. Von 1998 bis 2020 war er Fachhochschul-Professor und Fachbereichsleiter an der Fachhochschule Wiener Neustadt. Pinczolits betätigt sich als Buchautor und schreibt Artikel zum Thema Vertrieb und Verkauf.},
  langid = {ngerman},
  annotation = {Page Version ID: 235205851},
  file = {C:\Users\pober\Zotero\storage\NIT6B5UC\Karl_Pinczolits.html}
}

@article{kehtarnavazDevelopmentRealtimeImplementation2003,
  title = {Development and Real-Time Implementation of a Rule-Based Auto-Focus Algorithm},
  author = {Kehtarnavaz, N. and Oh, H. -J.},
  date = {2003-06-01},
  journaltitle = {Real-Time Imaging},
  shortjournal = {Real-Time Imaging},
  volume = {9},
  number = {3},
  pages = {197--203},
  issn = {1077-2014},
  doi = {10.1016/S1077-2014(03)00037-8},
  url = {https://www.sciencedirect.com/science/article/pii/S1077201403000378},
  urldate = {2023-02-22},
  abstract = {This paper presents the development and real-time implementation of a rule-based approach to passive auto-focusing for digital still cameras. The implementation is performed on the processor DM310 which is specifically manufactured by Texas Instruments for digital still cameras. The squared-gradient sharpness function is considered to measure the amount of high-frequency content in an out-of-focus image. This sharpness function is then used within a rule-based search algorithm to obtain the focused lens position via moving the lens head step-motor. The developed rule-based approach is compared to the commonly used global search and binary search algorithms in terms of focusing speed and power consumption. It is shown that the introduced rule-based search algorithm achieves a lower number of focusing iterations or faster focusing speed, and a lower number of steps or lower power consumption.},
  langid = {english},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\XH95UGFL\S1077201403000378.html}
}

@unpublished{keinathFachgesprachMitMarkus2023,
  title = {Fachgespräch Mit {{Markus Keinath}}},
  author = {Keinath, Markus},
  date = {2023-06}
}

@article{koenderinkStructureImages,
  title = {The Structure of Images},
  author = {Koenderink, Jan J},
  abstract = {In practice the relevant details of images exist only over a restricted range of scale. Hence it is important to study the dependence of image structure on the level of resolution. It seems clear enough that visual perception treats images on several levels of resolution simultaneously and that this fact must be important for the study of perception. However, no applicable mathematically formulated theory to deal with such problems appears to exist. In this paper it is shown that any image can be embedded in a oneparameter family of derived images (with resolution as the parameter) in essentially only one unique way if the constraint that no spurious detail should be generated when the resolution is diminished, is applied. The structure of this family is governed by the well known diffusionequation (a parabolic, linear, partial differential equation of the second order). As such the structure fits into existing theories that treat the front end of the visual system as a continuous stack of homogeneous layers, characterized by iterated local processing schemes. When resolution is decreased the images becomes less articulated because the extrem ("light and dark blobs") disappear one after the other. This erosion of structure is a simple process that is similar in every case. As a result any image can be described as a juxtaposed and nested set of light and dark blobs, wherein each blob has a limited range of resolution in which it manifests itself. The structure of the family of derived images permits a derivation of the sampling density required to sample the image at multiple scales of resolution. The natural scale along the resolution axis (leading to an informationally uniform sampling density) is logarithmic, thus the structure is apt for the description of size invariances.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\IEWXDGJL\Koenderink - The structure of images.pdf}
}

@article{kuiperVariablefocusLiquidLens2004,
  title = {Variable-Focus Liquid Lens for Miniature Cameras},
  author = {Kuiper, S. and Hendriks, B. H. W.},
  date = {2004-08-16},
  journaltitle = {Applied Physics Letters},
  shortjournal = {Appl. Phys. Lett.},
  volume = {85},
  number = {7},
  pages = {1128--1130},
  issn = {0003-6951, 1077-3118},
  doi = {10.1063/1.1779954},
  url = {https://pubs.aip.org/aip/apl/article/85/7/1128-1130/116928},
  urldate = {2023-06-29},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\5LQGX3B3\Kuiper und Hendriks - 2004 - Variable-focus liquid lens for miniature cameras.pdf}
}

@article{levi3DParticleTracking2005,
  title = {3-{{D Particle Tracking}} in a {{Two-Photon Microscope}}: {{Application}} to the {{Study}} of {{Molecular Dynamics}} in {{Cells}}},
  shorttitle = {3-{{D Particle Tracking}} in a {{Two-Photon Microscope}}},
  author = {Levi, Valeria and Ruan, QiaoQiao and Gratton, Enrico},
  date = {2005-04},
  journaltitle = {Biophysical Journal},
  shortjournal = {Biophys J},
  volume = {88},
  number = {4},
  eprint = {15653748},
  eprinttype = {pmid},
  pages = {2919--2928},
  issn = {0006-3495},
  doi = {10.1529/biophysj.104.044230},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1305386/},
  urldate = {2023-06-29},
  abstract = {We developed a method for tracking particles in three dimensions designed for a two-photon microscope, which holds great promise to study cellular processes because of low photodamage, efficient background rejection, and improved depth discrimination. During a standard cycle of the tracking routine (32 ms), the laser beam traces four circular orbits surrounding the particle in two z planes above and below the particle. The radius of the orbits is half of the x,y-width of the point spread function, and the distance between the z planes is the z-width of the point spread function. The z-position is adjusted by moving the objective with a piezoelectric-nanopositioner. The particle position is calculated on the fly from the intensity profile obtained during the cycle, and these coordinates are used to set the scanning center for the next cycle. Applying this method, we were able to follow the motion of 500-nm diameter fluorescent polystyrene microspheres moved by a nanometric stage in either steps of 20–100 nm or sine waves of 0.1–10 μm amplitude with 20 nm precision. We also measured the diffusion coefficient of fluorospheres in glycerol solutions and recovered the values expected according to the Stokes-Einstein relationship for viscosities higher than 3.7 cP. The feasibility of this method for live cell measurements is demonstrated studying the phagocytosis of protein-coated fluorospheres by fibroblasts.},
  pmcid = {PMC1305386},
  file = {C:\Users\pober\Zotero\storage\Q4NBFJEV\Levi et al. - 2005 - 3-D Particle Tracking in a Two-Photon Microscope .pdf}
}

@online{Linse,
  title = {Linse},
  url = {https://www.spektrum.de/lexikon/optik/linse/1885},
  urldate = {2023-06-28},
  abstract = {Linse, ein zumeist von zwei Kugelflächen begrenzter Körper aus durchsichtigem Stoff (meist Glas oder Kunststoff) mit definierter lichtbrechender…},
  langid = {ngerman},
  organization = {Spektrum.de},
  file = {C:\Users\pober\Zotero\storage\JGY9UGUK\1885.html}
}

@article{liuComparativeAnalysisThreeLevel2015,
  title = {A {{Comparative Analysis}} of the {{ThreeLevel NPC}} and {{ANPC Converter Loss Distribution}}},
  author = {Liu, He and Jiang, Jianguo and Luo, Wei},
  date = {2015-09-01},
  journaltitle = {Journal of Electrical Systems},
  shortjournal = {Journal of Electrical Systems},
  volume = {11},
  pages = {271--280},
  abstract = {In this paper, a comparative analysis of the three-level NPC and ANPC converter loss distribution are presented. Switching states and commutation principle of two topologies are analyzed and compared; Also, the loss distribution mathematical model of the two topologies has been established. The main feature of the three-level ANPC structure is to use the switching devices to replace the clamp diodes of the three-level NPC topology, by selecting the different zero voltage state. As a result, it can realize the loss distribution balance among the power devices. Then, the simulation results are shown the effectiveness of the three-level ANPC topology as it can realize the power devices loss equalize under different work conditions, and verified the validity of the proposed loss distribution mathematical model.},
  file = {C:\Users\pober\Zotero\storage\8H8AA6ST\Liu et al. - 2015 - A Comparative Analysis of the ThreeLevel NPC and A.pdf}
}

@article{liuComparativeAnalysisThreeLevel2015a,
  title = {A {{Comparative Analysis}} of the {{ThreeLevel NPC}} and {{ANPC Converter Loss Distribution}}},
  author = {Liu, He and Jiang, Jianguo and Luo, Wei},
  date = {2015-09-01},
  journaltitle = {Journal of Electrical Systems},
  shortjournal = {Journal of Electrical Systems},
  volume = {11},
  pages = {271--280},
  abstract = {In this paper, a comparative analysis of the three-level NPC and ANPC converter loss distribution are presented. Switching states and commutation principle of two topologies are analyzed and compared; Also, the loss distribution mathematical model of the two topologies has been established. The main feature of the three-level ANPC structure is to use the switching devices to replace the clamp diodes of the three-level NPC topology, by selecting the different zero voltage state. As a result, it can realize the loss distribution balance among the power devices. Then, the simulation results are shown the effectiveness of the three-level ANPC topology as it can realize the power devices loss equalize under different work conditions, and verified the validity of the proposed loss distribution mathematical model.}
}

@article{mahapatraAutoFocusAlgorithmBased,
  title = {Auto-{{Focus Algorithm Based On Maximum Gradient And Threshold}}},
  author = {Mahapatra, Sumeet and Kumar, Ramesh},
  langid = {english},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\59QVN3KC\Mahapatra und Kumar - Auto-Focus Algorithm Based On Maximum Gradient And.pdf}
}

@online{markSharpnessAcutanceResolution2014,
  title = {Sharpness, {{Acutance}} and {{Resolution}}},
  author = {Mark},
  date = {2014-05-05T11:10:02+00:00},
  url = {https://www.photoreview.com.au/tips/shooting/sharpness-acutance-and-resolution/},
  urldate = {2023-06-28},
  abstract = {We show you how these important parameters affect the appearance of your photos.},
  langid = {american},
  organization = {Photo Review},
  keywords = {Sharpness},
  file = {C:\Users\pober\Zotero\storage\ZAYHPLS3\sharpness-acutance-and-resolution.html}
}

@online{MatplotlibPyplotBoxplot,
  title = {Matplotlib.Pyplot.Boxplot — {{Matplotlib}} 3.7.2 Documentation},
  url = {https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html},
  urldate = {2023-07-12},
  file = {C:\Users\pober\Zotero\storage\46KCI6GB\matplotlib.pyplot.boxplot.html}
}

@article{maWiFiSensingChannel2020,
  title = {{{WiFi Sensing}} with {{Channel State Information}}: {{A Survey}}},
  shorttitle = {{{WiFi Sensing}} with {{Channel State Information}}},
  author = {Ma, Yongsen and Zhou, Gang and Wang, Shuangquan},
  date = {2020-05-31},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {52},
  number = {3},
  pages = {1--36},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3310194},
  url = {https://dl.acm.org/doi/10.1145/3310194},
  urldate = {2024-01-20},
  abstract = {With the high demand for wireless data traffic, WiFi networks have very rapid growth because they provide high throughput and are easy to deploy. Recently, Channel State Information (CSI) measured by WiFi networks is widely used for different sensing purposes. To get a better understanding of existing WiFi sensing technologies and future WiFi sensing trends, this survey gives a comprehensive review of the signal processing techniques, algorithms, applications, and performance results of WiFi sensing with CSI. Different WiFi sensing algorithms and signal processing techniques have their own advantages and limitations and are suitable for different WiFi sensing applications. The survey groups CSI-based WiFi sensing applications into three categories: detection, recognition, and estimation, depending on whether the outputs are binary/multi-class classifications or numerical values. With the development and deployment of new WiFi technologies, there will be more WiFi sensing opportunities wherein the targets may go beyond from humans to environments, animals, and objects. The survey highlights three challenges for WiFi sensing: robustness and generalization, privacy and security, and coexistence of WiFi sensing and networking. Finally, the survey presents three future WiFi sensing trends, i.e., integrating cross-layer network information, multi-device cooperation, and fusion of different sensors, for enhancing existing WiFi sensing capabilities and enabling new WiFi sensing opportunities. CCS Concepts: • General and reference → Surveys and overviews; • Hardware → Wireless devices.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\IEEJRE5S\WiFiSensing_YongsenMa_authorversion.pdf}
}

@misc{maximintegratedproductsMAX14515Pdf2008,
  title = {{{MAX14515}}.Pdf},
  author = {MAXIM Integrated Products},
  date = {2008},
  file = {C:\Users\pober\Zotero\storage\MQMG4TWL\MAX14515.pdf}
}

@article{mehrleMechatronicsSmartTechnologies2021,
  title = {Mechatronics - {{Smart Technologies}}},
  author = {Mehrle, Andreas},
  date = {2021},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\FNJ9YTEL\Mehrle - 2021 - Mechatronics - Smart Technologies.pdf}
}

@article{mehrleMechatronicsSmartTechnologies2023,
  title = {Mechatronics - {{Smart Technologies}}},
  author = {Mehrle, Andreas},
  date = {2023},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\EYEPUZ2T\Mehrle - 2023 - Mechatronics - Smart Technologies.pdf}
}

@book{meschedeOptikLichtUnd2008,
  title = {Optik, {{Licht}} Und {{Laser}}},
  author = {Meschede, Dieter},
  date = {2008},
  edition = {3},
  publisher = {Vieweg+Teubner Verlag},
  isbn = {3-8351-0143-9}
}

@inproceedings{newmanAnalysisGravitationalEffects2012,
  title = {Analysis of Gravitational Effects on Liquid Lenses ({{ANGEL}})},
  author = {Newman, Kevin and Stephens, Kyle},
  editor = {Navarro, Ramón and Cunningham, Colin R. and Prieto, Eric},
  date = {2012-09-13},
  pages = {84500G},
  location = {Amsterdam, Netherlands},
  doi = {10.1117/12.926520},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.926520},
  urldate = {2023-06-29},
  abstract = {Liquid lenses have been developed as a means for fast and reliable variable-focus optics by using an adjustable curvature in a liquid-liquid interface. The use of liquid lenses also provides the benefit of reducing the number of elements in a system, and providing a degree of freedom without any moving parts. Different methods for surface curvature actuation have been developed, including aperture adjustment, mechanical actuators, stimuli-responsive hydrogels, and mechanical-wetting. Current liquid lens designs are limited to small apertures (less than 4mm) and density-matching fluids to lessen the negative effects of gravity. By creating a lens intended for use in a microgravity environment, the aperture size can be increased by orders of magnitude, and optimal fluids can be used regardless of their density. Using a large-aperture (12mm) liquid lens, image and surface metrology was conducted using a fixed-focus configuration. The Software Configurable Optical Test System (SCOTS) method was utilized to test the effect of microgravity, standard gravity, and hypergravity on the liquid lens during parabolic flights. Under standard gravity, the RMS wavefront error (WFE) was 27 wavelengths, while microgravity conditions allowed an improvement to 17 wavelengths RMS WFE. Test performance can be improved by using lower viscosity fluids or longer duration microgravity flights. The experiment also served as an engineering demonstration for the SCOTS method in an environment where other methods of optical metrology would be impossible.},
  eventtitle = {{{SPIE Astronomical Telescopes}} + {{Instrumentation}}},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\QDC6S7ZU\Newman und Stephens - 2012 - Analysis of gravitational effects on liquid lenses.pdf}
}

@online{ngAnswerImageSharpness2013,
  title = {Answer to "{{Image}} Sharpness Metric"},
  author = {Ng, Andrew},
  date = {2013-07-26},
  url = {https://stackoverflow.com/a/17888026},
  urldate = {2023-05-22},
  organization = {Stack Overflow},
  file = {C:\Users\pober\Zotero\storage\E2Q7MPMP\image-sharpness-metric.html}
}

@unpublished{nikolausFachgesprach2023,
  title = {Fachgespräch},
  author = {Nikolaus, Felix},
  date = {2023-06}
}

@misc{obernesserEigenesBild2023,
  title = {Eigenes {{Bild}}},
  author = {Obernesser, Paul},
  date = {2023-06}
}

@online{ObjektiveMitFestbrennweite,
  title = {Objektive Mit {{Festbrennweite}} Der {{LT-Serie}} | {{Edmund Optics}}},
  url = {https://www.edmundoptics.de/f/lt-series-fixed-focal-length-lenses/39676/},
  urldate = {2023-06-30},
  file = {C:\Users\pober\Zotero\storage\HCYW9CYY\39676.html}
}

@online{ObjektiveMitFestbrennweitea,
  title = {Objektive Mit {{Festbrennweite}} Der {{Cx-Flüssiglinsen-Serie}}},
  url = {https://www.edmundoptics.de/f/liquid-lens-cx-series-fixed-focal-length-lenses/39466/},
  urldate = {2023-06-30},
  file = {C:\Users\pober\Zotero\storage\T29YSWXQ\39466.html}
}

@book{ogataModernControlEngineering2010,
  title = {Modern Control Engineering},
  author = {Ogata, Katsuhiko},
  date = {2010},
  series = {Prentice-{{Hall}} Electrical Engineering Series. {{Instrumentation}} and Controls Series},
  edition = {5th ed},
  publisher = {Prentice-Hall},
  location = {Boston},
  isbn = {978-0-13-615673-4},
  langid = {english},
  pagetotal = {894},
  keywords = {Automatic control,Control theory},
  file = {C:\Users\pober\Zotero\storage\DURKYIHT\Katsuhiko Ogata _ Modern Control Engineering 5th Edition.pdf}
}

@online{OptotuneEL1640TCPdf,
  title = {Optotune-{{EL-16-40-TC}}.Pdf},
  url = {https://static1.squarespace.com/static/5d9dde8d550f0a5f20b60b6a/t/64393a1cfe30773d7abd77f1/1681472030722/Optotune-EL-16-40-TC.pdf},
  urldate = {2023-04-20},
  file = {C:\Users\pober\Zotero\storage\LVXNDBWK\Optotune-EL-16-40-TC.pdf}
}

@online{OptotuneFocusTunable,
  title = {Optotune+focus+tunable+lenses+for+machine+vision.Pdf},
  url = {https://static1.squarespace.com/static/5d9dde8d550f0a5f20b60b6a/t/64394e1cf1e5c4626d902a25/1681477166377/Optotune+focus+tunable+lenses+for+machine+vision.pdf},
  urldate = {2023-04-20},
  file = {C:\Users\pober\Zotero\storage\2IZJ3QV8\Optotune+focus+tunable+lenses+for+machine+vision.pdf}
}

@inproceedings{parkFastAccurateAuto2008,
  title = {Fast and Accurate Auto Focusing Algorithm Based on Two Defocused Images Using Discrete Cosine Transform},
  author = {Park, Byung Kwan and Kim, Sung-Su and Chung, Dae-Su and Lee, Seongdeok and Kim, Chang Yeong},
  date = {2008-03-01},
  volume = {6817},
  doi = {10.1117/12.766253},
  abstract = {This paper describes the new method for fast auto focusing in image capturing devices. This is achieved by using two defocused images. At two prefixed lens positions, two defocused images are taken and defocused blur levels in each image are estimated using Discrete Cosine Transform (DCT). These DCT values can be classified into distance from the image capturing device to main object, so we can make distance vs. defocused blur level classifier. With this classifier, relation between two defocused blur levels can give the device the best focused lens step. In the case of ordinary auto focusing like Depth from Focus (DFF), it needs several defocused images and compares high frequency components in each image. Also known as hill-climbing method, the process requires about half number of images in all focus lens steps for focusing in general. Since this new method requires only two defocused images, it can save lots of time for focusing or reduce shutter lag time. Compared to existing Depth from Defocus (DFD) which uses two defocused images, this new algorithm is simple and accurate as DFF method. Because of this simplicity and accuracy, this method can also be applied to fast 3D depth map construction.},
  eventtitle = {Proceedings of {{SPIE}} - {{The International Society}} for {{Optical Engineering}}},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\NNNWR4AB\Park et al. - 2008 - Fast and accurate auto focusing algorithm based on.pdf}
}

@article{pertuzAnalysisFocusMeasure2013,
  title = {Analysis of Focus Measure Operators for Shape-from-Focus},
  author = {Pertuz, Said and Puig, Domenec and Garcia, Miguel Angel},
  date = {2013-05},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {46},
  number = {5},
  pages = {1415--1432},
  issn = {00313203},
  doi = {10.1016/j.patcog.2012.11.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320312004736},
  urldate = {2023-02-22},
  abstract = {Shape-from-focus (SFF) has widely been studied in computer vision as a passive depth recovery and 3D reconstruction method. One of the main stages in SFF is the computation of the focus level for every pixel of an image by means of a focus measure operator. In this work, a methodology to compare the performance of different focus measure operators for shape-from-focus is presented and applied. The selected operators have been chosen from an extensive review of the state-of-the-art. The performance of the different operators has been assessed through experiments carried out under different conditions, such as image noise level, contrast, saturation and window size. Such performance is discussed in terms of the working principles of the analyzed operators.},
  langid = {english},
  keywords = {Zu lesen},
  file = {C:\Users\pober\Zotero\storage\B7GMAICW\Pertuz et al. - 2013 - Analysis of focus measure operators for shape-from.pdf}
}

@article{pertuzAnalysisFocusMeasure2013a,
  title = {Analysis of Focus Measure Operators for Shape-from-Focus},
  author = {Pertuz, Said and Puig, Domenec and Garcia, Miguel Angel},
  date = {2013-05},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {46},
  number = {5},
  pages = {1415--1432},
  issn = {00313203},
  doi = {10.1016/j.patcog.2012.11.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320312004736},
  urldate = {2023-05-22},
  abstract = {Shape-from-focus (SFF) has widely been studied in computer vision as a passive depth recovery and 3D reconstruction method. One of the main stages in SFF is the computation of the focus level for every pixel of an image by means of a focus measure operator. In this work, a methodology to compare the performance of different focus measure operators for shape-from-focus is presented and applied. The selected operators have been chosen from an extensive review of the state-of-the-art. The performance of the different operators has been assessed through experiments carried out under different conditions, such as image noise level, contrast, saturation and window size. Such performance is discussed in terms of the working principles of the analyzed operators.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\IGUWUQUT\Pertuz et al. - 2013 - Analysis of focus measure operators for shape-from.pdf}
}

@inproceedings{podporaYUVVsRGB2014,
  title = {{{YUV}} vs {{RGB}}—{{Choosing}} a {{Color Space}} for {{Human-Machine Interaction}}},
  author = {Podpora, Michal and Korbaś, Grzegorz Paweł and Kawala-Janik, Aleksandra},
  date = {2014-09-29},
  pages = {29--34},
  doi = {10.15439/2014F206},
  url = {https://fedcsis.org/proceedings/2014/drp/206.html},
  urldate = {2023-06-29},
  abstract = {This paper describes and compares two color spaces – YUV and RGB, taking into account possible human-computer interaction applications. Human perception-oriented properties are compared, including not only file size or bandwidth, but also subjective visibility of artifacts. 1700 tests on a group of 170 people were performed to describe the subjective quality of compressed YUV and RGB images. The paper shows that the use of the YUV color space for a machine vision implementation can give better subjective image quality than the RGB color space. The authors conclude that YUV is better for machine vision implementations than RGB due to the perceptual similarities to the human vision.},
  eventtitle = {2014 {{Federated Conference}} on {{Computer Science}} and {{Information Systems}}},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\XTYRVTG6\Podpora et al. - 2014 - YUV vs RGB—Choosing a Color Space for Human-Machin.pdf}
}

@article{pouydebasqueVarifocalLiquidLenses2010,
  title = {Varifocal Liquid Lenses with Integrated Actuator, High Focusing Power and Low Operating Voltage Fabricated on 200~Mm Wafers},
  author = {Pouydebasque, Arnaud and Bridoux, Claudine and Jacquet, Fabrice and Moreau, Stéphane and Saint-Patrice, Damien and Bouvier, Christophe and Kopp, Christophe and Marchand, Gilles and Bolis, Sébastien and Sillon, Nicolas and Vigier-Blanc, Emmanuelle},
  date = {2010-01-01},
  journaltitle = {Procedia Engineering},
  shortjournal = {Procedia Engineering},
  series = {Eurosensor {{XXIV Conference}}},
  volume = {5},
  pages = {432--435},
  issn = {1877-7058},
  doi = {10.1016/j.proeng.2010.09.139},
  url = {https://www.sciencedirect.com/science/article/pii/S1877705810006867},
  urldate = {2023-06-22},
  abstract = {We developed an innovative type of varifocal liquid lens actuated by electrostatic parallel plates. The 3mm diameter lens is made of a polymer membrane that encapsulates a high permittivity liquid in a cavity on top of a glass wafer. Annular electrodes situated below the membrane and on the glass wafer form the electrostatic parallel plates actuator. Applying a voltage between the electrodes reduces the gap and pushes the liquid towards the center of the lens changing the curvature of the membrane. Compared to previous liquid lenses, significant outline improvement ({$<$}6×6×0.7~mm) and supply voltage reduction ({$<$}25~V ) is demonstrated. Wave front measurements indicate an optical power change of 8~m−1 at 22V RMS that can be further improved. The lenses were fabricated on 200~mm wafers using standard microelectronics processes that make our solution a promising small outline, low voltage and low cost candidate for auto-focus devices in camera phones.},
  langid = {english},
  keywords = {Electrostatic actuation,Liquid lens,Varifocal},
  file = {C\:\\Users\\pober\\Zotero\\storage\\D6I5V25A\\Pouydebasque et al. - 2010 - Varifocal liquid lenses with integrated actuator, .pdf;C\:\\Users\\pober\\Zotero\\storage\\PFAGPP5N\\S1877705810006867.html}
}

@article{reangsunteaTimeDomainEqualization1970,
  title = {Time {{Domain Equalization Method}} for {{DFTS-OFDM Signal}} without {{GI}} under {{Highly Mobile Environments}}},
  author = {Reangsuntea, Pongsathorn and Boonsrimuang, Pisit and Mori, Kazuo and Kobayashi, Hideo},
  date = {1970-01-01},
  journaltitle = {ECTI Transactions on Computer and Information Technology (ECTI-CIT)},
  shortjournal = {ECTI Transactions on Computer and Information Technology (ECTI-CIT)},
  volume = {9},
  pages = {150--159},
  doi = {10.37936/ecti-cit.201592.54418},
  abstract = {In highly time-varying fading channel, the Discrete Fourier Transform Spreading Orthogonal Frequency Division Multiplexing (DFTS-OFDM) signal would be damaged significantly by the inter-channel interference (ICI) due to the loss of orthogonality among subcarriers which leads a fatal degradation of bit error rate (BER) performance. To solve this problem, this paper proposes a time domain equalization (TDE) technique in conjunction with a time domain channel impulse response (CIR) estimation method for the DFTS-OFDM signal without using a guard interval (GI). The features of proposed method is to employ a time domain training sequence (TS) both for the estimation of time domain CIR at every sampling time and for removing the inter-symbol interference (ISI) incurred in the multipath fading channel. The proposed method also employs the TDE with a maximum likelihood (ML) estimation method in the demodulation of received time domain signal at every symbol instead of using the conventional Minimum Mean Square Error-Frequency Domain Equalization (MMSE-FDE) method. This paper presents various simulation results to demonstrate the effectiveness of proposed demodulation method for the DFTSOFDM signal without GI as comparing with the conventional MMSE-FDE and TDE methods both of usingGI under highly mobile environments.},
  file = {C:\Users\pober\Zotero\storage\4REWJDS4\Reangsuntea et al. - 1970 - Time Domain Equalization Method for DFTS-OFDM Sign.pdf}
}

@article{santosEvaluationAutofocusFunctions1997,
  title = {Evaluation of Autofocus Functions in Molecular Cytogenetic Analysis},
  author = {Santos, A. and Ortiz De Solórzano, C. and Vaquero, J. J. and Peña, J. M. and Malpica, N. and Del Pozo, F.},
  date = {1997-12},
  journaltitle = {Journal of Microscopy},
  shortjournal = {Journal of Microscopy},
  volume = {188},
  number = {3},
  pages = {264--272},
  issn = {0022-2720, 1365-2818},
  doi = {10.1046/j.1365-2818.1997.2630819.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2818.1997.2630819.x},
  urldate = {2023-06-01},
  abstract = {This work describes a systematic evaluation of several autofocus functions used for analytical fluorescent image cytometry studies of counterstained nuclei. Focusing is the first step in the automatic fluorescence in situ hybridization analysis of cells. Thirteen functions have been evaluated using qualitative and quantitative procedures. For the last of these procedures a figure-of-merit (FOM) is defined and proposed. This new FOM takes into account five important features of the focusing function. Our results show that functions based on correlation measures have the best performance for this type of image.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\VRC9XRXU\Santos et al. - 1997 - Evaluation of autofocus functions in molecular cyt.pdf}
}

@misc{saringBBASS202101Handout2021,
  title = {{{BBA-SS2021-01-Handout}}},
  author = {Säring, Prof. Dr. Dennis},
  date = {2021},
  organization = {FH Wedel}
}

@article{schlagImplementationAutomaticFocusing,
  title = {Implementation of {{Automatic Focusing Algorithms}} for a {{Computer Vision System}} with {{Camera Control}}},
  author = {Schlag, John F and Sanderson, Arthur C and Neuman, Charles P and Wimberly, Francis C},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\7H99TG9K\Schlag et al. - Implementation of Automatic Focusing Algorithms fo.pdf}
}

@online{SpatialFiltersLaplacian,
  title = {Spatial {{Filters}} - {{Laplacian}}/{{Laplacian}} of {{Gaussian}}},
  url = {https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm},
  urldate = {2023-05-09},
  file = {C:\Users\pober\Zotero\storage\87K3V4UG\log.html}
}

@online{SpatialFiltersLaplaciana,
  title = {Spatial {{Filters}} - {{Laplacian}}/{{Laplacian}} of {{Gaussian}}},
  url = {https://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm},
  urldate = {2023-04-12},
  file = {C:\Users\pober\Zotero\storage\P6KXX2GB\log.html}
}

@online{Stichprobenmittel,
  title = {Stichprobenmittel},
  url = {https://www.mathematik.uni-ulm.de/stochastik/lehre/ss04/statistik1/skript/node6.html},
  urldate = {2023-04-27},
  file = {C:\Users\pober\Zotero\storage\6JHQFE4F\node6.html}
}

@inreference{Stichprobenmittel2021,
  title = {Stichprobenmittel},
  booktitle = {Wikipedia},
  date = {2021-05-16T12:47:14Z},
  url = {https://de.wikipedia.org/w/index.php?title=Stichprobenmittel&oldid=212032665},
  urldate = {2023-04-27},
  abstract = {Das Stichprobenmittel, auch als Stichprobenmittelwert, arithmetischer Mittelwert oder arithmetisches Mittel bezeichnet, ist eine spezielle Schätzfunktion in der mathematische Statistik. Es spielt eine wichtige Rolle bei der Schätzung des Erwartungswertes von unbekannten Wahrscheinlichkeitsverteilungen und tritt auch bei der Konstruktion von Konfidenzintervallen und statistischen Tests auf. Sein empirisches Pendant ist der empirische Mittelwert. Er entspricht einer Realisierung des Stichprobenmittels.},
  langid = {ngerman},
  annotation = {Page Version ID: 212032665},
  file = {C:\Users\pober\Zotero\storage\HD2ZWZA2\Stichprobenmittel.html}
}

@inproceedings{studerDistanceMeasurementUsing2021,
  title = {Distance Measurement Using an {{Optotune}} Focus Tunable Lens},
  booktitle = {Photonic {{Instrumentation Engineering VIII}}},
  author = {Studer, Jennifer and Kurmulis, Sarah and Ciardi, Gustavo and Ventura, Mark},
  editor = {Soskind, Yakov and Busse, Lynda E.},
  date = {2021-03-05},
  pages = {9},
  publisher = {SPIE},
  location = {Online Only, United States},
  doi = {10.1117/12.2578267},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11693/2578267/Distance-measurement-using-an-Optotune-focus-tunable-lens/10.1117/12.2578267.full},
  urldate = {2023-04-20},
  eventtitle = {Photonic {{Instrumentation Engineering VIII}}},
  isbn = {978-1-5106-4221-8 978-1-5106-4222-5},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\9MTWDIQC\Studer et al. - 2021 - Distance measurement using an Optotune focus tunab.pdf}
}

@article{szeliskiComputerVisionAlgorithms,
  title = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  author = {Szeliski, Richard},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\P8LK3ZKT\Szeliski - Computer Vision Algorithms and Applications.pdf}
}

@online{toshibaApplication_note_en_20180803_AKX00303Pdf2018,
  title = {application\_note\_en\_20180803\_{{AKX00303}}.Pdf},
  author = {Toshiba},
  date = {2018-08-03},
  url = {https://toshiba.semicon-storage.com/info/application_note_en_20180803_AKX00303.pdf?did=61176},
  urldate = {2024-05-23},
  file = {C:\Users\pober\Zotero\storage\E8EDV2AY\application_note_en_20180803_AKX00303.pdf}
}

@online{UnderstandingCSIHandson,
  title = {Understanding {{CSI}} | {{Hands-on Wireless Sensing}} with {{Wi-Fi}}: {{A Tutorial}}},
  shorttitle = {Understanding {{CSI}} | {{Hands-on Wireless Sensing}} with {{Wi-Fi}}},
  url = {http://tns.thss.tsinghua.edu.cn/wst/docs/localhost/wst/docs/pre},
  urldate = {2024-01-20},
  abstract = {Channel state information (CSI) lays the foundation of most wireless sensing techniques, including Wi-Fi sensing, LTE sensing, and so on. CSI provides physical channel measurements in subcarrier-level granularity, and it can be easily accessed from the commodity Wi-Fi network interface controller (NIC).},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\ACLUQFT5\pre.html}
}

@article{valdezUnderstandingI2CBus2015,
  title = {Understanding the {{I2C Bus}}},
  author = {Valdez, Jonathan and Becker, Jared},
  date = {2015},
  abstract = {The I2C bus is a very popular and powerful bus used for communication between a master (or multiple masters) and a single or multiple slave devices. Figure 1 illustrates how many different peripherals may share a bus which is connected to a processor through only 2 wires, which is one of the largest benefits that the I2C bus can give when compared to other interfaces.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\TU8R2XJK\Valdez und Becker - 2015 - Understanding the I2C Bus.pdf}
}

@inproceedings{valentePerformanceAnalysisSinglephase2018,
  title = {Performance {{Analysis}} of a {{Single-phase GaN-based 3L-ANPC Inverter}} for {{Photovoltaic Applications}}},
  booktitle = {2018 {{IEEE}} 4th {{Southern Power Electronics Conference}} ({{SPEC}})},
  author = {Valente, Mauro and Iannuzzo, Francesco and Yang, Yongheng and Gurpinar, Emre},
  date = {2018-12},
  pages = {1--8},
  publisher = {IEEE},
  location = {Singapore, Singapore},
  doi = {10.1109/SPEC.2018.8635942},
  url = {https://ieeexplore.ieee.org/document/8635942/},
  urldate = {2024-01-23},
  abstract = {Nowadays, the power electronics converter design is challenged with a request of high efficiency and compactness for various applications. To tackle this, the research community and the industry have almost fully exploited the silicon technology, leading to the development of new power transistors. The Gallium-Nitride (GaN) HEMTs can be promising power devices to replace the traditional power devices. Therefore, the performances of GaN-based converters should be assessed to validate the effectiveness in terms of efficiency and power density. Moreover, among the available converter topologies , the performance of the three-level Neutral Point Clamped (NPC) family can be enhanced with the GaN HEMTs. In light of the above, in this paper, the performance of a GaN-based threelevel Active NPC (3L-ANPC) converter is evaluated in terms of power losses, volume impact of passive components, and output distortions. Simulations and experiments have been performed.},
  eventtitle = {2018 {{IEEE}} 4th {{Southern Power Electronics Conference}} ({{SPEC}})},
  isbn = {978-1-5386-8257-9},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\82X6K7NL\Valente et al. - 2018 - Performance Analysis of a Single-phase GaN-based 3.pdf}
}

@online{VariableFocusLenses,
  title = {Variable {{Focus Lenses}}: {{A-Series}} | {{Adjustable Lens Elements}} | {{Corning}}® {{Varioptic}}® {{Lenses}} | {{Corning}}},
  shorttitle = {Variable {{Focus Lenses}}},
  url = {https://www.corning.com/worldwide/en/products/advanced-optics/product-materials/corning-varioptic-lenses/variable-focus-lenses-a-series.html},
  urldate = {2023-06-23},
  abstract = {The variable focus A-Series adjustable lens elements enable variable focus functionality when designed into imaging or beam shaping lenses.},
  langid = {american},
  file = {C:\Users\pober\Zotero\storage\L8F8A2DM\variable-focus-lenses-a-series.html}
}

@article{vuBfSpectralSpatial2012,
  title = {\$\{\textbackslash bf \vphantom\}{{S}}\vphantom\{\}\_\{3\}\$: {{A Spectral}} and {{Spatial Measure}} of {{Local Perceived Sharpness}} in {{Natural Images}}},
  shorttitle = {\$\{\textbackslash bf \vphantom\}{{S}}\vphantom\{\}\_\{3\}\$},
  author = {Vu, C. T. and Phan, T. D. and Chandler, D. M.},
  date = {2012-03},
  journaltitle = {IEEE Transactions on Image Processing},
  shortjournal = {IEEE Trans. on Image Process.},
  volume = {21},
  number = {3},
  pages = {934--945},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/TIP.2011.2169974},
  url = {http://ieeexplore.ieee.org/document/6030937/},
  abstract = {This paper presents an algorithm designed to measure the local perceived sharpness in an image. Our method utilizes both spectral and spatial properties of the image: For each block, we measure the slope of the magnitude spectrum and the total spatial variation. These measures are then adjusted to account for visual perception, and then, the adjusted measures are combined via a weighted geometric mean. The resulting measure, i.e., (spectral and spatial sharpness), yields a perceived sharpness map in which greater values denote perceptually sharper regions. This map can be collapsed into a single index, which quantifies the overall perceived sharpness of the whole image. We demonstrate the utility of the measure for within-image and across-image sharpness prediction, no-reference image quality assessment of blurred images, and monotonic estimation of the standard deviation of the impulse response used in Gaussian blurring. We further evaluate the accuracy of in local sharpness estimation by comparing maps to sharpness maps generated by human subjects. We show that can generate sharpness maps, which are highly correlated with the human-subject maps.},
  langid = {english},
  keywords = {Sharpness},
  file = {C:\Users\pober\Zotero\storage\Y2YQHWQW\Vu et al. - 2012 - $ bf S _ 3 $ A Spectral and Spatial Measure of L.pdf}
}

@online{wangEndtoEndAutofocusCamera2021,
  title = {An {{End-to-End Autofocus Camera}} for {{Iris}} on the {{Move}}},
  author = {Wang, Leyuan and Zhang, Kunbo and Wang, Yunlong and Sun, Zhenan},
  date = {2021-06-28},
  eprint = {2106.15069},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.15069},
  urldate = {2023-02-22},
  abstract = {For distant iris recognition, a long focal length lens is generally used to ensure the resolution ofiris images, which reduces the depth of field and leads to potential defocus blur. To accommodate users at different distances, it is necessary to control focus quickly and accurately. While for users in motion, it is expected to maintain the correct focus on the iris area continuously. In this paper, we introduced a novel rapid autofocus camera for active refocusing ofthe iris area ofthe moving objects using a focus-tunable lens. Our end-to-end computational algorithm can predict the best focus position from one single blurred image and generate a lens diopter control signal automatically. This scene-based active manipulation method enables real-time focus tracking of the iris area ofa moving object. We built a testing bench to collect real-world focal stacks for evaluation of the autofocus methods. Our camera has reached an autofocus speed ofover 50 fps. The results demonstrate the advantages of our proposed camera for biometric perception in static and dynamic scenes. The code is available at https://github.com/Debatrix/AquulaCam.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Zu lesen},
  file = {C\:\\Users\\pober\\Zotero\\storage\\38M5DJZ8\\Wang et al. - 2021 - An End-to-End Autofocus Camera for Iris on the Mov.pdf;C\:\\Users\\pober\\Zotero\\storage\\MDC9B5V7\\2106.html}
}

@article{wuDeviceFreeWiFiHuman2017,
  title = {Device-{{Free WiFi Human Sensing}}: {{From Pattern-Based}} to {{Model-Based Approaches}}},
  shorttitle = {Device-{{Free WiFi Human Sensing}}},
  author = {Wu, Dan and Zhang, Daqing and Xu, Chenren and Wang, Hao and Li, Xiang},
  date = {2017-10},
  journaltitle = {IEEE Communications Magazine},
  shortjournal = {IEEE Commun. Mag.},
  volume = {55},
  number = {10},
  pages = {91--97},
  issn = {0163-6804},
  doi = {10.1109/MCOM.2017.1700143},
  url = {http://ieeexplore.ieee.org/document/8067692/},
  urldate = {2024-01-21},
  abstract = {Recently, device-free WiFi CSI-based human behavior recognition has attracted a great amount of interest as it promises to provide a ubiquitous sensing solution by using the pervasive WiFi infrastructure. While most existing solutions are pattern-based, applying machine learning techniques, there is a recent trend of developing accurate models to reveal the underlining radio propagation properties and exploit models for fine-grained human behavior recognition. In this article, we first classify the existing work into two categories: pattern-based and model-based recognition solutions. Then we review and examine the two approaches together with their enabled applications. Finally, we show the favorable properties of model-based approaches by comparing them using human respiration detection as a case study, and argue that our proposed Fresnel zone model could be a generic one with great potential for device-free human sensing using fine-grained WiFi CSI.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\HLF95EQS\Wu et al. - 2017 - Device-Free WiFi Human Sensing From Pattern-Based.pdf}
}

@article{xieVerticalCombfingerCapacitive2002,
  title = {Vertical Comb-Finger Capacitive Actuation and Sensing for {{CMOS-MEMS}}},
  author = {Xie, Huikai and Fedder, Gary K},
  date = {2002},
  abstract = {A new method for out-of-plane (vertical) electrostatic actuation and capacitive displacement-sensing that utilizes sidewall capacitance change of multiconductor comb ®ngers is analyzed and experimentally veri®ed. Combining the inherited in-plane (lateral) actuation and sensing capacities of comb ®ngers, three-dimensional actuation/sensing can be realized. A maskless post-CMOS micromachining process is employed and the fabrication is compatible with standard CMOS processes. Applications include an three-axis microstage, a z-axis accelerometer and a lateral-axis gyroscope that use the proposed vertical comb-®nger actuation/sensing method. The measured maximum vertical displacement of the microstage is 3.5 mm with a resonant frequency of 6.17 kHz. Measured sensitivity of the z-axis accelerometer is 0.5 mV/g with less than À40 dB cross-axis sensitivity, noise ¯oor 6 mg/HHz, and linear range from À27 to 27 g. The lateral-axis gyroscope design uses integrated comb drives for out-of-plane actuation, and is motivated by the desire to integrate three-axis gyroscopes on a single chip. The packaged gyroscope operates at atmospheric pressure with a sensitivity of 0.12 mV/o/s and the resonant frequency of the drive mode is thermomechanically tuned between 4.2±5.1 kHz. Resonant frequency matching between the drive and sense modes is realized by integrating a polysilicon heater inside the spring beams. \# 2002 Elsevier Science B.V. All rights reserved.},
  langid = {english},
  file = {C:\Users\pober\Zotero\storage\HBYVCVWX\Xie und Fedder - 2002 - Vertical comb-®nger capacitive actuation and sensi.pdf}
}

@article{xuComparisonContrastMeasurements2014,
  title = {A Comparison of Contrast Measurements in Passive Autofocus Systems for Low Contrast Images},
  author = {Xu, Xin and Wang, Yinglin and Zhang, Xiaolong and Li, Shunxin and Wang, Xiaofeng and Tang, Jinshan},
  date = {2014-03-01},
  journaltitle = {Multimedia Tools and Applications},
  shortjournal = {Multimedia Tools and Applications},
  volume = {69},
  doi = {10.1007/s11042-012-1194-x},
  abstract = {A number of contrast measurements have been investigated and compared in the literature. Each of them exhibits an ideal curve with a well defined peak standing for the best focused image. However, a focused image obtained in low light conditions possesses a small contrast value, which may be easily influenced by noise. In this case, contrast measurements may generate fluctuant curves with many local peaks. This paper presents a comparison among six contrast measurements in passive autofocus systems towards a non-previously researched object of low contrast images. The criterium to evaluate the performance of each measurement is unimodality. And we assess the similarity of the resulting curves with an ideal focus curve which exhibits a single peak and an absence of plateau. Experimental results from six typical image sequences indicate that Tenengrad and CMAN approaches yield the best performance, but it is still necessary to derive a more elaborated method because both methods fail to generate a single sharp peak in some circumstances.},
  keywords = {Zu lesen}
}

@article{yangAccurateRapidAutoFocus2020,
  title = {Accurate and {{Rapid Auto-Focus Methods Based}} on {{Image Quality Assessment}} for {{Telescope Observation}}},
  author = {Yang, Chunping and Chen, Minhao and Zhou, Fangfang and Li, Wei and Peng, Zhenming},
  date = {2020-01},
  journaltitle = {Applied Sciences},
  volume = {10},
  number = {2},
  pages = {658},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app10020658},
  url = {https://www.mdpi.com/2076-3417/10/2/658},
  urldate = {2023-04-18},
  abstract = {Aiming at improving the speed and accuracy of auto-focus for telescope observation, algorithms for image estimation and auto-focus were investigated and are discussed in this article. Based on the image quality assessment, the auto-focusing process of the telescope system is realized by using the mountain-climb search method. Several evaluation functions were tested in different scenarios. It is demonstrated that the Tenengrad image estimation function (IEF) is suitable for an instant and accurate auto-focus process of the telescope. Furthermore, we implemented sampling and dynamic adaptive focusing window (ES-DAFW) methods with the Tenengrad IEF to enhance the sensitivity and accuracy of the auto-focus process. The experimental results showed that our ES-DATW method can provide more accurate results in less time for the auto-focus process compared to the conventional approaches, especially for a sparse image. These results promise significant applications to the auto-focusing of other telescopes with image quality assessment.},
  issue = {2},
  langid = {english},
  keywords = {auto-focus,dynamic adaptive focusing window,image quality,telescope observation,Tenengrad function},
  file = {C:\Users\pober\Zotero\storage\ZUAWQEH6\Yang et al. - 2020 - Accurate and Rapid Auto-Focus Methods Based on Ima.pdf}
}

@article{yaoEvaluationSharpnessMeasures2006,
  title = {Evaluation of Sharpness Measures and Search Algorithms for the Auto-Focusing of High Magnification Images - Art. No. {{62480G}}},
  author = {Yao, Yi and Abidi, Besma and Narjes, Doggaz and Abidi, Mongi},
  date = {2006-06-01},
  journaltitle = {Proceedings of SPIE - The International Society for Optical Engineering},
  shortjournal = {Proceedings of SPIE - The International Society for Optical Engineering},
  volume = {6246},
  doi = {10.1117/12.664751},
  abstract = {Digital imaging systems with extreme zoom capabilities are traditionally found in astronomy and wild life monitoring. More recently, the need for such capabilities has extended to long range surveillance and wide area monitoring such as forest fires, airport perimeters, harbors, and waterways. Auto-focusing is an indispensable function for imaging systems designed for such applications. This paper studies the feasibility of an image based passive auto-focusing control for high magnification systems based on off-the-shelf telescopes and digital cameras/camcorders, with concentration on two associated elements: the cost function (usually the image sharpness measure) and the search strategy. An extensive review of existing sharpness measures and search algorithms is conducted and their performances compared. In addition, their applicability and adaptability to a wide range of high magnifications (50×\textasciitilde 1500×) are addressed. This study builds up the foundation for the development of auto-focusing schemes with particular applications to high magnification systems.},
  keywords = {Am lesen,Wichtig},
  file = {C:\Users\pober\Zotero\storage\F8VPH742\Yao et al. - 2006 - Evaluation of sharpness measures and search algori.pdf}
}

@incollection{yeoElectrowetting2008,
  title = {Electrowetting},
  booktitle = {Encyclopedia of {{Microfluidics}} and {{Nanofluidics}}},
  author = {Yeo, Leslie and Chang, Hsueh-Chia},
  editor = {Li, Dongqing},
  date = {2008},
  pages = {600--606},
  publisher = {Springer US},
  location = {Boston, MA},
  doi = {10.1007/978-0-387-48998-8_470},
  url = {https://doi.org/10.1007/978-0-387-48998-8_470},
  urldate = {2023-05-23},
  isbn = {978-0-387-48998-8},
  langid = {english}
}

@inreference{YUVFarbmodell2023,
  title = {YUV-Farbmodell},
  booktitle = {Wikipedia},
  date = {2023-03-23T08:20:06Z},
  url = {https://de.wikipedia.org/w/index.php?title=YUV-Farbmodell&oldid=232093580},
  urldate = {2023-06-12},
  abstract = {Das YUV-Farbmodell wird beim analogen Farbfernsehen nach den Normen PAL und NTSC verwendet. Es verwendet zur Darstellung der Farbinformation zwei Komponenten: die Luminanz (luma, Lichtstärke pro Fläche, d. h. Leuchtdichte) Y und die Chrominanz (Farbanteil, chroma), wobei diese aus den zwei Unterkomponenten U und V besteht.Häufig wird Farbmodell mit Farbraum verwechselt, einen YUV-Farbraum gibt es aber ebenso wenig wie etwa einen YPbPr- oder YCbCr-Farbraum (s. u.).},
  langid = {ngerman},
  annotation = {Page Version ID: 232093580},
  file = {C:\Users\pober\Zotero\storage\UX3Y4LJL\YUV-Farbmodell.html}
}

@article{zhangFastAccurateAutofocusing2014,
  title = {Fast and Accurate Auto-Focusing Algorithm Based on the Combination of Depth from Focus and Improved Depth from Defocus},
  author = {Zhang, Xuedian and Liu, Zhaoqing and Jiang, Minshan and Chang, Min},
  date = {2014-12-15},
  journaltitle = {Optics Express},
  shortjournal = {Opt. Express, OE},
  volume = {22},
  number = {25},
  pages = {31237--31247},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.22.031237},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-22-25-31237},
  urldate = {2023-02-22},
  abstract = {An auto-focus method for digital imaging systems is proposed that combines depth from focus (DFF) and improved depth from defocus (DFD). The traditional DFD method is improved to become more rapid, which achieves a fast initial focus. The defocus distance is first calculated by the improved DFD method. The result is then used as a search step in the searching stage of the DFF method. A dynamic focusing scheme is designed for the control software, which is able to eliminate environmental disturbances and other noises so that a fast and accurate focus can be achieved. An experiment is designed to verify the proposed focusing method and the results show that the method's efficiency is at least 3-5 times higher than that of the traditional DFF method.},
  langid = {english},
  keywords = {Am lesen,Image processing,Imaging systems,Laser beams,Optical devices,Optical imaging,Wavelet transforms},
  file = {C:\Users\pober\Zotero\storage\HD3LU3WE\Zhang et al. - 2014 - Fast and accurate auto-focusing algorithm based on.pdf}
}

@article{zhuReviewSurveyObjective2023,
  title = {Review: {{A Survey}} on {{Objective Evaluation}} of {{Image Sharpness}}},
  shorttitle = {Review},
  author = {Zhu, Mengqiu and Yu, Lingjie and Wang, Zongbiao and Ke, Zhenxia and Zhi, Chao},
  date = {2023-01},
  journaltitle = {Applied Sciences},
  volume = {13},
  number = {4},
  pages = {2652},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13042652},
  url = {https://www.mdpi.com/2076-3417/13/4/2652},
  urldate = {2023-04-26},
  abstract = {Establishing an accurate objective evaluation metric of image sharpness is crucial for image analysis, recognition and quality measurement. In this review, we highlight recent advances in no-reference image quality assessment research, divide the reported algorithms into four groups (spatial domain-based methods, spectral domain-based methods, learning-based methods and combination methods) and outline the advantages and disadvantages of each method group. Furthermore, we conduct a brief bibliometric study with which to provide an overview of the current trends from 2013 to 2021 and compare the performance of representative algorithms on public datasets. Finally, we describe the shortcomings and future challenges in the current studies.},
  issue = {4},
  langid = {english},
  keywords = {evaluation algorithm,evaluation metric,image quality,image sharpness,no-reference},
  file = {C:\Users\pober\Zotero\storage\8VNXEQMQ\Zhu et al. - 2023 - Review A Survey on Objective Evaluation of Image .pdf}
}
